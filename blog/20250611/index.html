<html>

<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <style type="text/css">
    
    body {
      font-family: "Times New Roman", "HelveticaNeue-Light", "Helvetica Neue Light", "Helvetica Neue", Helvetica, Arial, "Lucida Grande", sans-serif;
      font-weight: 200;
      font-size: 16px;
      margin-left: auto;
      margin-right: auto;
      width: 800px;
    }

    h1, h2{
      font-weight: 400;
      margin-top: 1.0em;
      margin-bottom: 1.0em;
    }

    h3{
      font-weight: 400;
      margin-top: 0.5em;
      margin-bottom: 0.5em;
    }

    p {
      font-size: 18px;
      font-weight: 200;
      line-height: 1.4;
    }

    code {
      font-size: 0.8rem;
      margin: 0 0.2rem;
      padding: 0.5rem 0.8rem;
      white-space: nowrap;
      background: #efefef;
      border: 1px solid #d3d3d3;
      color: #000000;
      border-radius: 3px;
    }

    pre>code {
      display: block;
      white-space: pre;
      line-height: 1.5;
      padding: 0;
      margin: 0;
    }

    pre.prettyprint>code {
      border: none;
    }

    .container {
      display: flex;
      align-items: center;
      justify-content: center
    }

    .image {
      flex-basis: 40%
    }

    .text {
      padding-left: 20px;
      padding-right: 20px;
    }

    .disclaimerbox {
      background-color: #eee;
      border: 1px solid #eeeeee;
      border-radius: 10px;
      -moz-border-radius: 10px;
      -webkit-border-radius: 10px;
      padding: 20px;
    }

    video.header-vid {
      height: 140px;
      border: 1px solid black;
      border-radius: 10px;
      -moz-border-radius: 10px;
      -webkit-border-radius: 10px;
    }

    img.header-img {
      height: 140px;
      border: 1px solid black;
      border-radius: 10px;
      -moz-border-radius: 10px;
      -webkit-border-radius: 10px;
    }

    img.rounded {
      border: 0px solid #eeeeee;
      border-radius: 10px;
      -moz-border-radius: 10px;
      -webkit-border-radius: 10px;

    }

    a:link,
    a:visited {
      color: #1367a7;
      text-decoration: none;
    }

    a:hover {
      color: #208799;
    }

    td.dl-link {
      height: 160px;
      text-align: center;
      font-size: 22px;
    }

    hr {
      border: 0;
      height: 1px;
      background-image: linear-gradient(to right, rgba(0, 0, 0, 0), rgba(0, 0, 0, 0.75), rgba(0, 0, 0, 0));
    }

    .abstract-container {
      background-color: #f8f9fa;
      padding: 0.5em;
      border-radius: 5px;
      margin: 0.5em 0;
    }

  </style>

<link rel="icon" href="./image/0.png">
  <title>Darwin Godel Machine</title>
</head>

<body data-new-gr-c-s-check-loaded="14.1093.0" data-gr-ext-installed="">
  <center>
    <span style="font-size:36px; color:#5C5DBD; font-family: Varela Round,sans-serif; font-weight: 700; line-height: 65px;">Share the Best: I</span>
    <br>
    <span style="font-size:28px">Gaining Inspiration from Darwinian Evolution: Towards Self-Referential and Self-Improving AI System</span>
    <br>
    <br>
  </center>

  <hr>
  
  <br>

  <center> <img src="./image/1.png" alt="alt text" style="width: 100%; object-fit: cover; max-width:100%;"></a> </center>
  <p style="text-align:justify; text-justify:inter-ideograph;">
    <left>
      Illustration of incorporating Darwinian exploration into Gödel machine.
    </left>
  </p>

  <center> <h2> <strong> Beginning </strong> </h2> </center>
  <div class="abstract-container">
      <p style="text-align:justify; text-justify:inter-ideograph;">
        <left>
          One tantalizing path toward that goal is an AI that improves itself by rewriting its own code, including any code responsible for learning. This idea, also known as a Gödel Machine, was proposed by Jürgen Schmidhuber decades ago, which is a hypothetical self-improving AI. 
        </left>
        <br>
        <left>
          Recently, researchers from University of British Columbia, Vector Institute, Sakana AI, and Canada CIFAR AI Chair proposed a system (Darwin Gödel Machine, DGM) that harnesses the principles of open-ended algorithms like Darwinian evolution to search for improvements that empirically improve performance.
        </left>
        <br>
        <left>
          DGMs leverage foundation models to propose code improvements, and use recent innovations in open-ended algorithms to search for a growing library of diverse, high-quality AI agents. Experiments show that DGMs improve themselves the more compute they are provided. In line with the clear trend that AI systems that rely on learning ultimately outperform those designed by hand, there is a potential that DGMs could soon outperform hand-designed AI systems.
        </left>
      </p>
  </div>

  <br>
  <hr>

  <center> <h2> <strong> The Evolution Pipeline </strong> </h2> </center>
  <center> <img class="center" src="./image/2.png" width="800px"></p> </center>

  <p style="text-align:justify; text-justify:inter-ideograph;">
    <left>
      <strong style="font-weight: 900"> Dataset Construction and Statistics. </strong>
      (a) The data construction pipeline for VGBench, SpatialScore, and SpatialScore-Hard;
      (b) Representative examples from distinct categories in SpatialScore;
      (c) Data distribution statistics across VGBench, SpatialScore, and SpatialScore-Hard.
    </left>
  </p>

  <br>

  <center> <img class="center" src="./resources/SpatialScore_statistics.png" width="800px"> </center>
  <p style="text-align:justify; text-justify:inter-ideograph;">
    <center> <strong style="font-weight: 900; font-size: 18px"> Data sources and task category statistics visualization of SpatialScore. </strong> </center>
  </p>

  <br>

  <center> <img class="center" src="./resources/VGBench_statistics.png" width="800px"> </center>
  <p style="text-align:justify; text-justify:inter-ideograph;">
    <center> <strong style="font-weight: 900; font-size: 18px"> Data sources and task category statistics visualization of VGBench. </strong> </center>
  </p>

  <br>
  <hr>

  <center> <h2> <strong> SpatialAgent Architecture </strong> </h2> </center>
  <center> <img class="center" src="./resources/architecture.png" width="800px"> </center>
  <p>
    <left>
      <strong style="font-weight: 900"> Architecture and Workflow of SpatialAgent. </strong>
      (a) Specialized spatial understanding tools integrated in SpatialAgent;
      (b) The <i>Plan-Execute</i> paradigm for hierarchical task decomposition and stepwise execution;
      (c) The <i>ReAct</i> paradigm for iterative interaction and dynamic strategy refinement.
    </left>
  </p>

  <br>
  <hr>

  <center> <h2> <strong> Results </strong> </h2> </center>
  <h3> <center> <strong> Quantitative Results </strong> </center> </h3>
  
  <center> <img class="center" src="./resources/quantitative_results_1.png" width="800px"></p> </center>
  <p>
    <left>
      <strong style="font-weight: 900"> Quantitative Results on SpatialScore. </strong>
      Here, Count., Obj-Loc., Pos-Rel., Dist., Obj-Prop., and Cam.&IT. refer to Counting, Object Localization, 3D Positional Relation, Depth & Distance, Object Properties, and Camera & Image Transformation, respectively.
      Results with the best and second best results are <strong>bolded</strong> and <u>underlined</u>, respectively.
    </left>
  </p>

  <br>
  
  <center> <img class="center" src="./resources/quantitative_results_2.png" width="800px"> </center>
  <p>
    <left>
      <strong style="font-weight: 900"> Quantitative Results on SpatialScore-Hard. </strong>
      Our SpatialAgent demonstrates substantially greater performance improvements on this carefully curated, challenging subset, highlighting its specialized capabilities for spatial understanding tasks.
    </left>
  </p>

  <br>
  
  <center> <img class="center" src="./resources/quantitative_results_3.png" width="800px"> </center>
  <p>
    <left>
      <strong style="font-weight: 900"> Quantitative Results on VGBench. </strong>
      Here, Homo., Pose-Est., 3D-Recon., Tracking, and Obj-Pos. denote Homography Matrix, Pose Estimation, 3D Reconstruction, Point Tracking, and Object Position, respectively.
      Results with the best and second best results are are <strong>bolded</strong> and <u>underlined</u>.
    </left>
  </p>

  <br>

  <h3> <center> <strong> Qualitative Results </strong> </center> </h3>
  <p> <img class="center" src="./resources/qualitative_results.png" width="800px"> </p>
  <p>
    <left>
      <strong style="font-weight: 900"> Qualitative Results. </strong>
      We present the comprehensive reasoning process of SpatialAgent against the direct responses of other models.
      While occasional errors occur due to tool execution or interpretation mistakes, these limitations are expected to diminish as MLLMs continue to advance.
    </left>
  </p>

  <br>

  <hr>

  <center> <h2> <strong> References </strong> </h2> </center>
  <p> [1] Zhang, Jenny, et al. "Darwin Godel Machine: Open-Ended Evolution of Self-Improving Agents." arXiv preprint arXiv:2505.22954 (2025).
[2] https://sakana.ai/dgm/ </p>

  <br>
  <br>

</body><grammarly-desktop-integration data-grammarly-shadow-root="true"></grammarly-desktop-integration>

</html>