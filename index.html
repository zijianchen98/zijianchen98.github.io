<!DOCTYPE HTML>
<html lang="en">

<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Zijian Chen</title>

  <meta name="author" content="Zijian Chen">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" href="data:image/svg+xml, <svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üßê</text></svg>">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
    <tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr style="padding:0px">
                <td style="padding:1%;width:70%;vertical-align:middle">
                  <p style="text-align:center">
                    <name>Zijian Chen „ÄåÈôàÂ≠êÂÅ•„Äç</name>
                  </p>
                  <p>
                    I am currently a first-year PhD Student of <a href="https://multimedia.sjtu.edu.cn/">Multimedia Lab</a> at <a href="https://sjtu.edu.cn/">Shanghai Jiao Tong University (SJTU)</a>, advised by <a href="https://ee.sjtu.edu.cn/FacultyDetail.aspx?id=24&infoid=66&flag=66">Prof. Guangtao Zhai</a> and <a href="https://ee.sjtu.edu.cn/FacultyDetail.aspx?id=14&infoid=66&flag=66">Prof. Wenjun Zhang</a>.
                    Previously, I received my M.E. degree from <a href="https://www.ecust.edu.cn/">East China University of Science and Technology</a> in June 2023, and B.S. degree in EE from <a href="https://www.wzu.edu.cn/">Wenzhou University</a> in June 2020. </p>
                  <p>
                    I'm generally interested in <strong>image/video quality assessment</strong>, <strong>large multimodal models</strong>, especially <strong>all-round evaluation</strong>, and AI4Humanity (Oracle bone character processing).
                    My ultimate goal is to build models with human-like general intelligence that can seamlessly understand, generate, and reason across multiple modalities.
                  </p>  
                  <p>
                    <font color="red"> I'm always eager to communicate and cooperate, so feel free to contact me!!! </font>
                  </p>

                  <p>
                    Email: zijian.chen@sjtu.edu.cn  &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;   <!-- WeChat: xxxxx_ --> 
                  </p>
                  <p style="text-align:center">
                    <a href="mailto:zijian.chen@sjtu.edu.cn">Email</a> &nbsp/&nbsp
                    <!-- <a href="data/xxxxx_CV.pdf">CV</a> &nbsp/&nbsp -->
                    <a href="https://scholar.google.com/citations?hl=en&user=NSR4UkMAAAAJ">Google Scholar</a>
                    &nbsp/&nbsp
                    <a href="https://github.com/zijianchen98/">Github</a> &nbsp/&nbsp
                    <a href="https://www.zhihu.com/people/amorzhu-ling-feng">Zhihu</a>
                    <!-- <a href="https://www.linkedin.com/in/xxxxx/">LinkedIn</a> -->
                  </p>
                </td>
                <td style="padding:1%;width:30%;max-width:30%">
                  <a href="images/czj.jpg"><img style="width:90%;max-width:90%" alt="profile photo" src="images/czj.jpg" class="hoverZoomLink"></a>
                </td>
              </tr>
            </tbody>
          </table>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:10px;width:100%;vertical-align:middle">
                  <heading>News</heading>
                  <ul>
                    <li> [2025.04] Start internship at <strong><a href="https://www.shlab.org.cn/">Shanghai AI Laboratory</a></strong> as a research intern, Shanghai (on-site). </li>
                    <li> [2025.04] I will attend <strong><a href="https://iclr.cc/">ICLR 2025</a></strong> in person. See you in Singapore! </li>
                    <li> [2025.02] One paper about (<strong><a href="https://ieeexplore.ieee.org/abstract/document/10896716">image debanding</a></strong>) has been accepted by <strong><a href="https://ieee-cas.org/publication/tcsvt">IEEE TCSVT 2025</a></strong>. </li>
                    <li> [2025.01] One paper (<strong><a href="https://github.com/zijianchen98/OBI-Bench">OBI-Bench</a></strong>) has been accepted by <strong><a href="https://iclr.cc/">ICLR 2025</a></strong>. </li>
                    <li> [2024.11] One paper (<strong>the first naturalness evaluation for AI-generated images </strong>, <strong><a href="https://github.com/zijianchen98/AGIN">AGIN</a></strong>), has been accepted by <strong><a href="https://ieee-cas.org/publication/tcsvt">IEEE TCSVT 2025</a></strong>. </li>
                    <li> [2024.09] One paper (<strong><a href="https://github.com/zijianchen98/GAIA">GAIA</a></strong>) has been accepted by <strong><a href="https://neurips.cc/Conferences/2024">NeurIPS 2024 D&B Track</a></strong> and selected as <strong>Spotlight</strong>. </li>
                    <li> [2024.02] One paper (<a href="https://ieeexplore.ieee.org/abstract/document/10438477">BAND-2k</a>) has been accepted by <a href="https://ieee-cas.org/publication/tcsvt">IEEE TCSVT 2024</a>. </li>
                    <li> [2024.01] One paper (<a href="https://ieeexplore.ieee.org/abstract/document/10558429">FS-BAND</a>) has been accepted by <a href="https://2024.ieee-iscas.org/">ISCAS 2024</a>. </li>
                  </ul>
                </td>
              </tr>
            </tbody>
          </table>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:10px;width:100%;vertical-align:middle">
                  <heading>Preprints</heading>
                  <p>
                    * denotes equal contribution, and <sup>‚Ä†</sup> denotes corresponding author.
                  </p>
                </td>
              </tr>
            </tbody>
          </table>
          

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:5px;width:28%;vertical-align:middle">
                  <img src="images/SoccerAgent.png" alt="SoccerAgent" width="200">
                </td>
                <td style="padding:5px;width:70%;vertical-align:middle">
                  <a href="https://jyrao.github.io/SoccerAgent/">
                    <papertitle>Multi-Agent System for Comprehensive Soccer Understanding</papertitle>
                  </a>
                  <br>
                  <a href="https://jyrao.github.io">Jiayuan Rao*</a>, <a href="https://github.com/lizifeng1209">Zifeng Li*</a>, <strong>Haoning Wu</strong>, <a href="https://annzhanglion.github.io/">Ya Zhang</a>, <a href="https://cmic.sjtu.edu.cn/wangyanfeng/">Yanfeng Wang<sup>‚Ä†</sup></a>, <a href="https://weidixie.github.io/">Weidi Xie<sup>‚Ä†</sup></a>
                  <br>
                  <em>arXiv</em>, 2025. &nbsp; <font color="red"> <strong>(NEW)</strong></font>
                  <br>
                  <a href="https://jyrao.github.io/SoccerAgent/">project page</a>
                  /
                  <a href="https://arxiv.org/abs/2505.03735/">arXiv</a>
                  /
                  <a href="https://github.com/jyrao/SoccerAgent/">code</a>
                  <br>
                  <p> In this work, we present SoccerBench, the largest and most comprehensive soccer-specific benchmark, along with a multi-agent system, SoccerAgent, for soccer understanding.
                  </p>
                </td>
              </tr>
            </tbody>
          </table>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:5px;width:28%;vertical-align:middle">
                  <img src="MRGen/resources/teaser.png" alt="MRGen" width="200">
                </td>
                <td style="padding:5px;width:70%;vertical-align:middle">
                  <a href="https://haoningwu3639.github.io/MRGen/">
                    <papertitle>MRGen: Segmentation Data Engine for Underrepresented MRI Modalities</papertitle>
                  </a>
                  <br>
                  <strong>Haoning Wu*</strong>, <a href="https://zhaoziheng.github.io/">Ziheng Zhao*</a>, <a href="https://annzhanglion.github.io/">Ya Zhang</a>, <a href="https://cmic.sjtu.edu.cn/wangyanfeng/">Yanfeng Wang<sup>‚Ä†</sup></a>, <a href="https://weidixie.github.io/">Weidi Xie<sup>‚Ä†</sup></a>
                  <br>
                  <em>arXiv</em>, 2024. &nbsp; <font color="red"> <strong>(NEW)</strong></font>
                  <br>
                  <a href="https://haoningwu3639.github.io/MRGen/">project page</a>
                  /
                  <a href="https://arxiv.org/abs/2412.04106/">arXiv</a>
                  /
                  <a href="https://github.com/haoningwu3639/MRGen/">code</a>
                  <br>
                  <p> In this work, we establish a novel paradigm for generative models in medical applications: controllably synthesizing data for underrepresented modalities.
                  </p>
                </td>
              </tr>
            </tbody>
          </table>




          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:10px;width:100%;vertical-align:middle">
                  <heading>Publications -- IQA/VQA</heading>
                  <p>
                    * denotes equal contribution, and <sup>‚Ä†</sup> denotes corresponding author.
                  </p>
                </td>
              </tr>
            </tbody>
          </table>
                  
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:5px;width:28%;vertical-align:middle">
                  <img src="images/UniSoccer.png" alt="UniSoccer" width="200">
                </td>
                <td style="padding:5px;width:70%;vertical-align:middle">
                  <a href="https://jyrao.github.io/UniSoccer/">
                    <papertitle>Towards Universal Soccer Video Understanding</papertitle>
                  </a>
                  <br>
                  <a href="https://jyrao.github.io">Jiayuan Rao*</a>, <strong>Haoning Wu*</strong>, <a href="https://scholar.google.nl/citations?user=0TvdOEcAAAAJ&hl=en/">Hao Jiang</a>, <a href="https://annzhanglion.github.io/">Ya Zhang</a>, <a href="https://cmic.sjtu.edu.cn/wangyanfeng/">Yanfeng Wang<sup>‚Ä†</sup></a>, <a href="https://weidixie.github.io/">Weidi Xie<sup>‚Ä†</sup></a>
                  <br>
                  <em>CVPR</em>, 2025. &nbsp; <font color="red"> <strong>(NEW)</strong></font>
                  <br>
                  <a href="https://jyrao.github.io/UniSoccer/">project page</a>
                  /
                  <a href="https://arxiv.org/abs/2412.01820/">arXiv</a>
                  /
                  <a href="https://github.com/jyrao/UniSoccer/">code</a>
                  <br>
                  <p> In this work, we present the first visual-language foundation model tailored for soccer video understanding, which can be applied various downstream tasks.
                  </p>
                </td>
              </tr>
            </tbody>
          </table>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:5px;width:28%;vertical-align:middle">
                  <img src="MegaFusion/resources/teaser.png" alt="MegaFusion" width="200">
                </td>
                <td style="padding:5px;width:70%;vertical-align:middle">
                  <a href="https://haoningwu3639.github.io/MegaFusion/">
                    <papertitle>MegaFusion: Extend Diffusion Models towards Higher-resolution Image Generation without Further Tuning</papertitle>
                  </a>
                  <br>
                  <strong>Haoning Wu*</strong>, <a href="https://github.com/ShaochengShen">Shaocheng Shen*</a>, <a href="https://qianghu-huber.github.io/qianghuhomepage/">Qiang Hu</a>, <a href="https://mediabrain.sjtu.edu.cn/xiaoyun-zhang/">Xiaoyun Zhang<sup>‚Ä†</sup></a>, <a href="https://annzhanglion.github.io/">Ya Zhang</a>, <a href="https://cmic.sjtu.edu.cn/wangyanfeng/">Yanfeng Wang</a>
                  <br>
                  <em>WACV</em>, 2025. &nbsp; <font color="red"> <strong>(NEW)</strong></font>
                  <br>
                  <a href="https://haoningwu3639.github.io/MegaFusion/">project page</a>
                  /
                  <a href="https://arxiv.org/abs/2408.11001/">arXiv</a>
                  /
                  <a href="https://github.com/ShaochengShen/MegaFusion/">code</a>
                  <br>
                  <p> In this work, we propose a tuning-free strategy to extend the higher-resolution image generation capabilities of existing diffusion models. </p>
                </td>
              </tr>
            </tbody>
          </table>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:5px;width:28%;vertical-align:middle">
                  <img src="MatchTime/resources/architecture.png" alt="MatchTime" width="200">
                </td>
                <td style="padding:5px;width:70%;vertical-align:middle">
                  <a href="https://haoningwu3639.github.io/MatchTime/">
                    <papertitle>MatchTime: Towards Automatic Soccer Game Commentary Generation</papertitle>
                  </a>
                  <br>
                  <a href="https://jyrao.github.io">Jiayuan Rao*</a>, <strong>Haoning Wu*</strong>, <a href="https://verg-avesta.github.io/">Chang Liu</a>, <a href="https://cmic.sjtu.edu.cn/wangyanfeng/">Yanfeng Wang<sup>‚Ä†</sup></a>, <a href="https://weidixie.github.io/">Weidi Xie<sup>‚Ä†</sup></a>
                  <br>
                  <em>EMNLP</em>, 2024. &nbsp; <font color="red"> <strong> (Oral Presentation)</strong></font>
                  <br>
                  <a href="https://haoningwu3639.github.io/MatchTime/">project page</a>
                  /
                  <a href="https://arxiv.org/abs/2406.18530/">arXiv</a>
                  /
                  <a href="https://github.com/jyrao/MatchTime/">code</a>
                  <br>
                  <p> In this work, we focus on building an visual-language model for automatic soccer game commentary generation. </p>
                </td>
              </tr>
            </tbody>
          </table>

          

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:10px;width:100%;vertical-align:middle">
                  <heading>Publications -- Oracle Bone Inscriptions (OBI) Processing</heading>
                  <p>
                    * denotes equal contribution, and <sup>‚Ä†</sup> denotes corresponding author.
                  </p>
                </td>
              </tr>
            </tbody>
          </table>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:5px;width:28%;vertical-align:middle">
                  <img src="MatchTime/resources/architecture.png" alt="MatchTime" width="200">
                </td>
                <td style="padding:5px;width:70%;vertical-align:middle">
                  <a href="https://haoningwu3639.github.io/MatchTime/">
                    <papertitle>MatchTime: Towards Automatic Soccer Game Commentary Generation</papertitle>
                  </a>
                  <br>
                  <a href="https://jyrao.github.io">Jiayuan Rao*</a>, <strong>Haoning Wu*</strong>, <a href="https://verg-avesta.github.io/">Chang Liu</a>, <a href="https://cmic.sjtu.edu.cn/wangyanfeng/">Yanfeng Wang<sup>‚Ä†</sup></a>, <a href="https://weidixie.github.io/">Weidi Xie<sup>‚Ä†</sup></a>
                  <br>
                  <em>EMNLP</em>, 2024. &nbsp; <font color="red"> <strong> (Oral Presentation)</strong></font>
                  <br>
                  <a href="https://haoningwu3639.github.io/MatchTime/">project page</a>
                  /
                  <a href="https://arxiv.org/abs/2406.18530/">arXiv</a>
                  /
                  <a href="https://github.com/jyrao/MatchTime/">code</a>
                  <br>
                  <p> In this work, we focus on building an visual-language model for automatic soccer game commentary generation. </p>
                </td>
              </tr>
            </tbody>
          </table>


          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:10px;width:100%;vertical-align:middle">
                  <heading>Publications -- Early Works</heading>
                  <p>
                    * denotes the sole student author.
                  </p>
                </td>
              </tr>
            </tbody>
          </table>
          
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:5px;width:28%;vertical-align:middle">
                  <img src="images/iet-its.jpg" alt="MatchTime" width="200">
                </td>
                <td style="padding:5px;width:70%;vertical-align:middle">
                  <a href="https://ietresearch.onlinelibrary.wiley.com/doi/full/10.1049/itr2.12330">
                    <papertitle>Spatial‚Äêtemporal correlation graph convolutional networks for traffic forecasting</papertitle>
                  </a>
                  <br>
                  Ru Huang (Master's Advisor), <strong>Zijian Chen*</strong>, <a href="https://scholar.google.com.hk/citations?user=E6zbSYgAAAAJ&hl=zh-CN">Guangtao Zhai</a>, <a href="https://scholar.google.com.hk/citations?user=4SUAgfAAAAAJ&hl=zh-CN">Jianhua He</a>, <a href="https://scholar.google.com.hk/citations?user=kboVs84AAAAJ&hl=zh-CN">Xiaoli Chu</a>
                  <br>
                  <em>IET Intelligent Transport Systems</em>, 2023. &nbsp;
                  <br>
                  <p> In this work, we propose a novel architecture, named spatial-temporal correlation graph convolutional networks (STCGCN), for traffic prediction. </p>
                </td>
              </tr>
            </tbody>
          </table>


          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:5px;width:28%;vertical-align:middle">
                  <img src="images/TNSE.jpg" alt="MatchTime" width="200">
                </td>
                <td style="padding:5px;width:70%;vertical-align:middle">
                  <a href="https://ieeexplore.ieee.org/abstract/document/9928404">
                    <papertitle>A Graph Entropy Measure From Urelement to Higher-Order Graphlets for Network Analysis</papertitle>
                  </a>
                  <br>
                  Ru Huang (Master's Advisor), <strong>Zijian Chen*</strong>, <a href="https://scholar.google.com.hk/citations?user=E6zbSYgAAAAJ&hl=zh-CN">Guangtao Zhai</a>, <a href="https://scholar.google.com.hk/citations?user=4SUAgfAAAAAJ&hl=zh-CN">Jianhua He</a>, <a href="https://scholar.google.com.hk/citations?user=kboVs84AAAAJ&hl=zh-CN">Xiaoli Chu</a>
                  <br>
                  <em>IEEE Transactions on Network Science and Engineering</em>, 2022. &nbsp;
                  <br>
                  <p> In this work, we introduce an unbiased graphlet estimation strategy to obtain both urelement and higher-order statistics for network analysis. </p>
                </td>
              </tr>
            </tbody>
          </table>


          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:10px;width:100%;vertical-align:middle">
                  <heading>Reviewer Service</heading>
                </td>
              </tr>
            </tbody>
          </table>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:0px;width:75%;vertical-align:middle">
                  <ul>  
                    <li> Annual Conference on Neural Information Processing Systems (<strong>NeurIPS</strong> <a href="https://neurips.cc/Conferences/2025">2025</a>) </li>
                    <li> International Conference on Learning Representations (<strong>ICLR</strong> <a href="https://iclr.cc/">2025</a>) </li>
                    <li> ACM Multimedia (<strong>ACM MM</strong> <a href="https://2025.acmmm.org/">2025</a>) </li>
                    <li> IEEE Transactions on Multimedia (<strong>TMM</strong> <a href="https://signalprocessingsociety.org/publications-resources/ieee-transactions-multimedia">2025</a>) </li>
                    <li> IEEE Intelligent Transportation Systems Magazine (<strong>ITSM</strong> <a href="https://ieee-itss.org/pub/its-magazine/">2024</a>) </li>
                  </ul>
                </td>
              </tr>
            </tbody>
          </table>
          
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:10px;width:100%;vertical-align:middle">
                  <heading>Talks</heading>
                </td>
              </tr>
            </tbody>
          </table>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <!-- <td style="padding:5px;width:28%;vertical-align:middle">
                  <img src="images/SJTU_logo.png" style="width:80%;max-width:200px">
                </td> -->
                <td style="padding:0px;width:75%;vertical-align:middle">
                  <ul>
                    <li> [2024.11] <strong>AI+Virtual Simulation: Empowering Display Device Development</strong> (The 16th China Display Academic Conference) </li>
                  </ul>
                </td>
              </tr>
            </tbody>
          </table>


          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:10px;width:100%;vertical-align:middle">
                  <heading>Awards</heading>
                </td>
              </tr>
            </tbody>
          </table>
          
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <!-- <td style="padding:5px;width:28%;vertical-align:middle">
                  <img src="images/SJTU_logo.png" style="width:80%;max-width:200px">
                </td> -->
                <td style="padding:0px;width:75%;vertical-align:middle">
                  <ul>
                    <li> [2023] <strong>Excellent Graduates in Shanghai</strong> (for postgraduates) </li>
                    <li> [2021] National Second Prize (National Graduate Electronics Design Contest) </li>
                    <li> [2019] First Prize in Zhejiang Province (National Undergraduate Electronics Design Contest) </li>
                  </ul>
                </td>
              </tr>
            </tbody>
          </table>

          <script type="text/javascript" id="clustrmaps" src="//clustrmaps.com/map_v2.js?d=p7iHbnJc-FcNcM90lORZz5_R574L4XTf-yVYZZtqIIY&cl=ffffff&w=a"></script>

          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:0px">
                  <p style="text-align:left;font-size:small;"> Updated in Jun. 2025
                  </p>
                  <p style="text-align:right;font-size:small;">
                    Thanks <a href="https://jonbarron.info/"> Jon Barron</a> for this amazing website template</a>.
                  </p>
                </td>
              </tr>
            </tbody>
          </table>
        </td>
      </tr>
    </tbody>
  </table>
</body>

</html>